{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download \"music\" portiion of audioset dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir audioset_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from audioset_download import Downloader\n",
    "# d = Downloader(root_path='/mnt/sdb/audioset-download', labels=[\"Music\"], n_jobs=36, download_type='eval', copy_and_replicate=False)\n",
    "# d.download(format = 'wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inpsect how many files from 'balanced dataset' are in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "AUSIOSET_PATH = Path('/mnt/shared/alpaca/audioset_minigimbob/audio')\n",
    "AUDIOCAP_PATH = Path('musiccaps-public.csv') # you can download this from kaggle\n",
    "\n",
    "ytid_filepath_dict = {file.stem[1:12]: file for file in AUSIOSET_PATH.rglob('*') if file.is_file() and file.suffix == '.wav'}\n",
    "# make filename_list a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "caption_df_original = pd.read_csv(AUDIOCAP_PATH)\n",
    "\n",
    "caption_df_filtered = caption_df_original[caption_df_original['ytid'].isin(ytid_filepath_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5521, 5480)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_df_original), len(caption_df_filtered)\n",
    "# (5521, 5480), we have 41 missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytid_caption_dict = caption_df_filtered.set_index('ytid')['caption'].to_dict()\n",
    "# substitute special characters to space\n",
    "special_characetrs = ['.', ',', '!', '?', ':', ';', '\"', \"'\", '(', ')', '[', ']', '{', '}', '<', '>', '/', '\\\\', '|', '@', '#', '$', '%', '^', '&', '*', '+', '=', '~', '`']\n",
    "for ytid, caption in ytid_caption_dict.items():\n",
    "    for special_characetrs in special_characetrs:\n",
    "        caption = caption.replace(special_characetrs, ' ')\n",
    "        caption = caption.lower()\n",
    "    ytid_caption_dict[ytid] = caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocab before text normalization: 5435\n"
     ]
    }
   ],
   "source": [
    "# text normalization\n",
    "# count total number of words in the captions (size of vocab)\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def get_word_counter(captions):\n",
    "    word_counter = Counter()\n",
    "    for caption in captions:\n",
    "        words = re.findall(r'\\w+', caption)\n",
    "        for word in words:\n",
    "            word_counter[word] += 1\n",
    "    return word_counter\n",
    "\n",
    "before_text_normalization = get_word_counter(ytid_caption_dict.values())\n",
    "print(f'size of vocab before text normalization: {len(before_text_normalization)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5480/5480 [01:23<00:00, 65.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocab after text normalization: 4250\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "get_lemma = spacy.load('en_core_web_sm')\n",
    "\n",
    "'''\n",
    "(before) This recording contains breaking and 32 shooting sounds. There is also a lot of deep rumbling noise. The whole audio is panned to the right side of the speakers.\n",
    "(after) this record contain break and 32 shoot sound . there be also a lot of deep rumble noise . the whole audio be pan to the right side of the speaker .\n",
    "'''\n",
    "def process_caption(item):\n",
    "    ytid, caption = item\n",
    "    words = re.findall(r'\\w+|\\.', caption)\n",
    "    normalized_caption = ' '.join([token.lemma_ for word in words for token in get_lemma(word)])\n",
    "    return ytid, normalized_caption\n",
    "\n",
    "# requires about 20GB of DRAM, ~ 3 min with 40 cores (serial ~ 16 min)\n",
    "with ProcessPoolExecutor(max_workers=(os.cpu_count())) as executor:\n",
    "    results = list(tqdm(executor.map(process_caption, ytid_caption_dict.items()), total=len(ytid_caption_dict)))\n",
    "\n",
    "ytid_caption_dict = dict(results)\n",
    "\n",
    "after_text_normalization = get_word_counter(ytid_caption_dict.values())\n",
    "print(f'size of vocab after text normalization: {len(after_text_normalization)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'vocab size reduced of {1 - len(after_text_normalization) / len(before_text_normalization):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if ytid are all unique -> yes\n",
    "len(ytid_caption_dict), len(set(ytid_caption_dict.keys()))\n",
    "\n",
    "# check the maximum word length of the captions (not the number of alphabet) -> 136\n",
    "# max([len(caption.split()) for caption in ytid_caption_dict.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. save audio as tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the wav file using torchaudio and save it as 16khz in the wavs folder\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "# Function to load and process each file\n",
    "def process_file(file):\n",
    "    wav, sr = torchaudio.load(file)  # Load the audio file\n",
    "    shape = wav.shape\n",
    "\n",
    "    return file, shape, sr, wav.shape[1] / sr\n",
    "\n",
    "# Main function to process files in parallel\n",
    "def process_files_parallel(file_set):\n",
    "    shape_dict = {}\n",
    "    sr_dict = {}\n",
    "    duration_dict = {}\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        results = list(tqdm(executor.map(process_file, file_set), total=len(file_set)))\n",
    "\n",
    "    for result in results:\n",
    "        file, shape, sr, duration = result\n",
    "        shape_dict[file] = shape\n",
    "        sr_dict[file] = sr\n",
    "        duration_dict[file] = duration\n",
    "\n",
    "    return shape_dict, sr_dict, duration_dict\n",
    "\n",
    "shape_dict, sr_dict, duration_dict = process_files_parallel(ytid_filepath_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# print unique sr_dict values and its counts\n",
    "print({k: v for k, v in sorted(Counter(sr_dict.values()).items(), key=lambda item: item[1])})\n",
    "# print unique duration in increasing order\n",
    "print({k: v for k, v in sorted(Counter(duration_dict.values()).items(), key=lambda item: item[0])}, end='\\n\\n')\n",
    "# min = 9.5 sec, max = 10.007 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TARGET_WAV_LEN = 16000 * 10\n",
    "\n",
    "def process_file(audio_path):\n",
    "    wav, sr = torchaudio.load(audio_path)  # Load the audio file\n",
    "    wav = wav.mean(dim=0, keepdim=True)  # Convert to mono\n",
    "    wav = torchaudio.transforms.Resample(sr, TARGET_SR)(wav)  # Resample to 16kHz\n",
    "    wav = wav.squeeze()\n",
    "    \n",
    "    # fill the audio file with itself if the length is less than TARGET_WAV_LEN\n",
    "    wavlen = wav.shape[0]\n",
    "    \n",
    "    if wavlen < TARGET_WAV_LEN:\n",
    "        wav = torch.cat([wav, wav[:TARGET_WAV_LEN - wavlen]])\n",
    "    elif wavlen > TARGET_WAV_LEN:\n",
    "        wav = wav[:TARGET_WAV_LEN]\n",
    "            \n",
    "    # get the caption of the audio file\n",
    "    file_id = audio_path.stem[1:12]\n",
    "    # extract the caption for corresponding track_id\n",
    "    caption = ytid_caption_dict[file_id]\n",
    "        \n",
    "    return (wav, caption)\n",
    "\n",
    "# Main function to process files in parallel\n",
    "def process_files_parallel(file_set):\n",
    "    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        wav_caption_list = list(tqdm(executor.map(process_file, file_set), total=len(file_set)))\n",
    "    \n",
    "    return wav_caption_list\n",
    "\n",
    "wav_caption_list = process_files_parallel(ytid_filepath_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('pkls/musiccaps_dataset.pkl')\n",
    "# save with pickle\n",
    "import pickle\n",
    "pickle.dump(wav_caption_list, open(output_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
